"# RNN-Language-Model" 

##### Two main approaches

#### 1- character level 

#### 2- word level

using  LSTM layers to model recurrent neural network to predict next word or char
given the previous ones



#### TO DO

- [ ] Using state_is_tuple in char level

- [x] printing number of trainable parameter

- [ ] running word level with new changes

- [ ] using estimator

- [ ] converting string data to indexes takes long

- [ ] code is dirty I've got to clean it

- [x] saving is not handled in seq2seq

